{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Kg9pViwBXO"
      },
      "source": [
        "# Install the necessary Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hraicEbuBEj"
      },
      "outputs": [],
      "source": [
        "! pip install openai\n",
        "! pip install pydub\n",
        "! pip install fpdf\n",
        "! pip install PyPDF2\n",
        "! pip install chromadb\n",
        "! pip install langchain\n",
        "! pip install tiktoken\n",
        "! pip install unstructured\n",
        "! pip install pypdf pdfminer\n",
        "! pip install youtube-transcript-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLtO7xnv_oP"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "HKhfvajctc98"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import requests\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "import io\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from IPython.display import Audio, display\n",
        "import PyPDF2\n",
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, WebBaseLoader, YoutubeLoader, DirectoryLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import os\n",
        "\n",
        "\n",
        "# Get your OpenAI API Key by logging onto https://platform.openai.com/api-keys\n",
        "\n",
        "# Set your OpenAI API key where it says <INSERT_API_KEY>, remove the <>\n",
        "os.environ['OPEN_API_KEY'] = \"<INSERT_API_KEY>\"\n",
        "client = OpenAI(api_key=\"<INSERT_API_KEY>\")\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=\"<INSERT_API_KEY>\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4QrnwOv3jd"
      },
      "source": [
        "# Chat Completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "50hw3gSLuIB1",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "# Function to interact with the OpenAI GPT-3 API using streaming\n",
        "def stream_gpt(query, model):\n",
        "\n",
        "\n",
        "    # Create a chat completion request with streaming enabled\n",
        "    completion = client.chat.completions.create(\n",
        "        # Specify the GPT model to use\n",
        "        model = model,\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\" : \"You are a helpful assistant.\"},\n",
        "            # User's input\n",
        "            {\"role\": \"user\", \"content\" : query}\n",
        "        ],\n",
        "        # Enable streaming to receive partial results\n",
        "        stream=True\n",
        "    )\n",
        "     # Iterate over the streaming response and print the generated content\n",
        "    for chunk in completion:\n",
        "        if(chunk.choices[0].delta.content != None):\n",
        "        # Extract the generated content from the streaming response and print it\n",
        "          print(chunk.choices[0].delta.content, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9XpOI9FyqAD"
      },
      "outputs": [],
      "source": [
        "# Call the stream_gpt function with the specified query and model\n",
        "res = stream_gpt(query = \"When did AI originate?\", model = \"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clYXnnu-3mFU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gHRr6K73mZ4"
      },
      "source": [
        "# Chat with PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "0Nk7eaXK7JzS"
      },
      "outputs": [],
      "source": [
        "paper = \"<INSERT_PDF_PATH>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "zHiXNXoahfLx"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(paper)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "okI2Hgto20_U"
      },
      "outputs": [],
      "source": [
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "Lh7o__dp21cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1754b0b9-bb3d-4320-c1d7-4565da8a3aa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This entry is about the Wall Street Journal and the various topics it covers. It includes sections on health, style, sports, world news, business, U.S. news, politics, opinion, arts and culture, lifestyle, personal finance, and real estate. It also mentions some of the writers and podcasts associated with the Wall Street Journal.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 204
        }
      ],
      "source": [
        "index.query(\"Please summarize this entry.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfN5bpzChfZr"
      },
      "source": [
        "# Chat with Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPwx8oF_htge"
      },
      "outputs": [],
      "source": [
        "# Insert the website url\n",
        "url = \"<INSERT_WEBSITE_URL>\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(url)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "l8pKnQjK5G-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "id": "vb5a-PTX5b8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.query(\"What is the latest developement on AI?\")"
      ],
      "metadata": {
        "id": "3po_bd_T5HnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b4f05724-b530-4f80-b03c-40215d8c44d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The latest development on AI is the emergence of deep learning as a pivotal force, characterized by layered synthetic neural networks that attempt to replicate the intricacies of the human brain and establish pathways to remarkable opportunities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5qZAfpPh-Au"
      },
      "source": [
        "# Chat With YouTube Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJZ_TDJkija2"
      },
      "outputs": [],
      "source": [
        "# Insert the video url\n",
        "youtube_url = \"<INSERT_VIDEO_URL>\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert the video ID at the end of the URL after v=\n",
        "loader = YoutubeLoader(\"<INSERT_VIDEO_ID>\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "XtBYNd2I5mGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "id": "KIiYiarE5mKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.query(\"Summarive this video.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zDl_FSAS5mPK",
        "outputId": "6474c1b2-fd8f-416d-e95f-acd249eb7e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Tahajjud is important because it is a time when Allah subhanahu wa ta'ala descends to the lower Heaven and comes closer to the world to listen to The Plea, to listen to the problems, to listen to the cries, and to listen to the wants and needs of the people. Whoever asks Allah during this time will get it continuously. Praying during this time will bring a great amount of sweetness, peace, and happiness.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}